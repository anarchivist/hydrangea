#!/usr/bin/env ruby
require 'rubygems'
require 'tempfile'
require 'fastercsv'
require 'pp'
require  File.join(File.dirname(__FILE__), '../config/environment.rb')

RAILS_DEFAULT_LOGGER.auto_flushing = 1

class Ingestor

  def initialize(file=nil, directory=nil)

     Module.const_set("AimsDocument", AimsDocument)
     ###### The directory to be processed ######
     @file = file
     @directory = directory
     ###### Configuration Stuff Here #######
     @fedora_user = 'fedoraAdmin'
     @fedora_pass = 'fedoraAdmin'
   #  @fedora_uri = "http://#{@fedora_user}:#{@fedora_pass}@hydra-aims-dev.stanford.edu/fedora/"
    @fedora_uri = "http://#{@fedora_user}:#{@fedora_pass}@localhost:8983/fedora/"
     @fedora_ns = "druid"
  #   @solr_uri =  "http://hydra-aims-dev.stanford.edu/solr/"
  @solr_uri =  "http://localhost:8983/solr/development"

     ###### Register the Repos #######
     # => http://projects.mediashelf.us/wiki/active-fedora/ActiveFedora_Console_Tour

     ActiveFedora::SolrService.register(@solr_uri, :verify_mode=>:none)
     Fedora::Repository.register(@fedora_uri)

     ###### You can keep a list of file extension to be ingested here, with a specification of their control group #####
     ###### Typically, most files are ingested with a control group "M" (managed). XML is often stored as "X" (inline XML), but
     ###### can also be stored as "M". Yeah.
     # => http://www.fedora-commons.org/documentation/3.0b1/userdocs/digitalobjects/objectModel.html

     ### To configure this, there are two hashes, which you can define file extensions to match a DS label/id.
     ### The syntax is {".pdf" => { "id" => "pdf", "label" => "A PDF of the Document"}}
     ### If there is no label or id, the base file name (minus extension) is used.
     ### Since IDs must be unique, If there are multiple datastreams with the same extension,
     ### the first file will be given the ID, with the following files using their filenames as their IDs.
     ### NOT USING THESE FOR AIMS INGESTOR
     #@managed = {".pdf" => { "id" => "PDF", "label" =>"Document PDF"} , ".tiff" => "", ".jpg" => { "label" => "Thumbnail"}, ".xml" => ""}
     #@inline = {".dc" => {'id' => 'dublin_core', "label" => "Metadata"}}
  end #initialize

  
  
  

     def process()
       if @file.nil?
          puts "AIMS INGESTOR => This script ingests files output from FTK using a CSV file generated by lib/html_to_csv.rb" 
          puts "you can run the script like so=>    $:  script/ingestor.rb Gouldoutput.csv "
       elsif File.exists?(@file)
         FasterCSV.open("#{@file}", :headers => true).each do |row|
            ingest_object(row)
          end #do
       else
         puts "Error: #{@file} does not exists."
        end #if @directory.nil?
     end #process

     #
     #  This method creates a "Managed" datastream object.
     #  Just realized spaces in file names cause problems in the ID/Label, so there's hokey quick fix for that.
     def create_file_ds(f, id= nil, label=nil)
       puts "creating file ds for #{f} "
       if id.nil? || id.empty?
         id = File.basename(f, File.extname(f)).gsub(" ", "-")
       end
       if label.nil? || label.empty?
         label = File.basename(f, File.extname(f)).gsub(" ", "-")
       end

       ActiveFedora::Datastream.new(:dsID=>id, :controlGroup=>"M" , :blob=>File.open(f), :dsLabel=>label)

     end  #create_file_ds

     #
     # This method creates an "Inline" datastream object
     #
     def create_inline_ds(f, id= nil, label=nil)
       puts "creating inline ds for #{f} "
       if id.nil?
         id = File.basename(f, File.extname(f)).gsub(" ", "-")
       end
       if label.nil?
         label = File.basename(f, File.extname(f)).gsub(" ", "-")
       end
       #this helps format the XML a bit
       xml = Nokogiri::XML(open(f))
       ds = ActiveFedora::Datastream.new(:dsID=>id, :controlGroup=>"X", :dsLabel=>label)
       ds.content = xml.to_xml
       return ds
     end  #create_inline_ds


     # This method is passed a row from the CSV that represents a AIMS objects. 
     # The AIMS object has at least one parent object (which has the descriptive metadata and "aggregriate" files (text, jp2000s, pdfs), and multiple child objects
     # (the archival content file itself, like a WordPerfect, MS Word, Excel Spreadsheet, or regualar JPG.))

     def ingest_object(row)

      obj = File.join(@directory, File.basename(row["exportedAs"].gsub('\\', '/')))
      sourceFile = File.join(obj,File.basename(row["exportedAs"].gsub('\\', '/')))
       
      if File.exists?(obj)
       # Gets a new PID
       pid = Nokogiri::XML(open(@fedora_uri + "/management/getNextPID?xml=true&namespace=#{@fedora_ns}", {:http_basic_authentication=>[@fedora_user, @fedora_pass]})).xpath("//pid").text
 
       fedora_obj = AimsDocument.new(:pid => pid)
       fedora_obj.label = File.basename(obj)
       fedora_obj.save
       
        # generate the Hydra:RightsMetadata XML for rights management. 
        dsid = 'rightsMetadata'
        xml_content = fedora_obj.datastreams_in_memory[dsid].content
        ds = Hydra::RightsMetadata.from_xml(xml_content)
        pid = fedora_obj.pid
        ds.pid = pid
        ds.dsid = dsid
        fedora_obj.datastreams_in_memory[dsid] = ds
        permissions = {"group"=>{"public"=>"read", "archivist" => "edit", "researcher" => "read", "patron" => 'read', "donor" => 'edit' }, "person" => {"archivist1" => "edit"}}
        ds.update_permissions(permissions)
        permissions = {"group" => {"public"=>"read"}}
        ds.update_permissions(permissions)
        fedora_obj.save
       
       # Now go through the object's directory and add the files to fedora. 
       Dir["#{obj}/**/**"].each do |f|
         
         #damn OS X spotlight. 
         unless f.include?('DS_Store')
          
          # text files and pdfs get added as datastreams to the parent object. 
          #the "content" (the file that was actually described by FTK)files get added as their own objects
          # jp2000s are not currently being stored in Fedora since they will eventually be hosted on Stanford's image server,  
          # so for now they're being copied into a directory named after the Fedora parent object's PID and place on a webserver. 
          if f == sourceFile   
               cpid = Nokogiri::XML(open(@fedora_uri + "/management/getNextPID?xml=true&namespace=#{@fedora_ns}", {:http_basic_authentication=>[@fedora_user, @fedora_pass]})).xpath("//pid").text
            
               child_obj = FileAsset.new(:pid => cpid)
               child_obj.label = File.basename(f)
               dc = child_obj.datastreams['descMetadata']
               dc.extent_values << File.size(f)
               fedora_obj.add_relationship(:has_part, child_obj )
               fedora_obj.add_relationship(:has_collection_member, child_obj)
               puts "processing:#{f} for objectID #{cpid}"
               ext = File.extname(f)
               id = "DS1"
               label = File.basename(f)
               child_obj.add_datastream(create_file_ds(f, id, label ))
               child_obj.save
               print f + "\n"
               
          elsif f =~ /(.*)\.(txt)/
             fedora_obj.add_datastream(create_file_ds(f, File.basename(f), File.basename(f)))
          elsif f =~ /(.*)\.(pdf)/
             fedora_obj.add_datastream(create_file_ds(f, 'pdf', "#{File.basename(f)}.pdf"))
          elsif f =~  /(.*)\.(jp2)/      
             jp2_dir = File.join('/tmp', fedora_obj.pid.gsub("druid:", "druid_"))
             FileUtils.mkdir_p(jp2_dir) unless File.directory?(jp2_dir)
             FileUtils.cp(f, jp2_dir, :verbose => true)
          else
            puts "not a file to ingest ==> #{f}"
          end #if
         end #unless
       end #dir
         
         # Now we process the CSV File for Metadata to be added to the Object's descMetadata and properties DS'es 
         dm = fedora_obj.datastreams["descMetadata"]
         prop = fedora_obj.datastreams["properties"]
         
         # The Labels column in the CSV has a lot of metadata that describes the object, so we need to process the values
         # and map them into the AIMS document model.  
         # Here's an example of the output from this column => "D,S:Evolution (Biology),S:Natural history,CM:5.25,O,A,I,P"
         # Breakdown => D = "Document"; "S:Evolution (Biology)" / S:Natural history => Subject Headings; 
         # CM:5.25 => (Computer Media) 5.25 inch. floppy diskettes;  O,A,I,P are permissions (Not really doing anything with these yet. )
         
         # Lets split this row up into indiviual parts of an array. 
         labels = row["labels"].split(',')
         
         # This is were I define the mappings from the CSV columns into the AIMS metadata spec. 
         loutput = {"subjects" => [], "access" => []}
         doc_values = { "D" => "Document", "S" => "Spreadsheet", "E" => "Email", "IM" => "Image", "V" => "Video", "SO" => "Sound"} 
         comp_values = {"CM:5.25" => "5.25 inch. floppy diskettes", "CM:3.5" => "3.5 inch. floppy diskettes", "CM:P" => "Punch cards", "CM:T" => "Tape" }
         access_values = {"O" => "owner", "A" => "Archivists", "I" => "Invited", "P" =>"Public", "M"=>"Reading"}
        
        # Let's go thru all labels and match them to their defined values. 
         labels.each do |l|
           if doc_values.has_key?(l)
             loutput["doctype"] = doc_values[l]
           elsif comp_values.has_key?(l)
             loutput["mediatype"] = comp_values[l]
           elsif access_values.has_key?(l)
             loutput["access"] << access_values[l]
           elsif l.include?("S:")
             loutput["subjects"] << l.gsub("S:", '') 
          end #if
         end #do
         
         # With the above example output, we would now have a hash (loutput) that looks like :
         #   {"doctype" => "Document", "subjects" => ["Evolution (Biology)", "Natural history"], "mediatype" => "5.25 inch. floppy diskettes", access => [ "owner", "Archivists", "Invited", "Public", "Reading"] }
         # We'll add this to the AIMS Document object below....
         
         # Now lets add some boilerplate values to the properties DS. 
         prop.collection_values << "Steven J. Gould"
         prop.pages_values << number_of_pages(fedora_obj) # this just counts the # of txt files in the parent object. 
         prop.path_values << row['path']
         prop.file_size_values << row['size']
         prop.md5_values << row['md5']
         prop.sha1_values << row['sha1']
         prop.file_type_values << row['type']
         prop.filname_values << File.basename(obj)
         
         # In FTK, a Bookmark is made for each Subseries. 
         dm.isPartOf_values = row["subseries"].gsub(/[0-9]|Bookmark:/,"").strip
         dm.source_values << row['filename']
         
         # Now lets finish by adding the values from the labels column....
         dm.type_values << loutput['doctype']
         dm.format_values <<  loutput["mediatype"]
         loutput['subjects'].each { |s| dm.subject_values << s.gsub("S:", "") }
        
        dm.save
        prop.save
        fedora_obj.save

        solr_doc = fedora_obj.to_solr
        
        # For some reason there seems to be a bug in solrizer or something that doesn't add this.
        solr_doc <<  Solr::Field.new( :discover_access_group_t => "public" )
        ActiveFedora::SolrService.instance.conn.update(solr_doc)
     
      end #if exists?    
     end #ingest_object


     # this makes the json for the nytimes book reader app
    

    #this method gets the number of pages for a document
    def number_of_pages(fedora_obj)
      len = []
      fedora_obj.datastreams.keys.each do |x|
        len << x if x.include?('.txt')
      end
      len.length
    end #number_of_pages

end #class

#========== This is the equivalent of a java main method ==========#
if __FILE__ == $0
 ingestor = Ingestor.new(ARGV[0], ARGV[1])
 ingestor.process
end
